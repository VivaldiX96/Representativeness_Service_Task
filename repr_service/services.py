import random
from pydantic import BaseModel, confloat
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

#### We define the representativeness of an object as: 
#### 1/(1 + average_distance_of_k_neighbors)


NUMBER_OF_MODELS: int = None # "L" - number of parts into which we split 
                        # the whole group of training arrays; also the number of models
                        # from which the averaged prediction will be obtained






# Function generating a set of arrays of the chosen size 'size' with arrays_amount elements;
# It returns a list of arrays of random numbers to be used as dependent variables in ML training
async def generate_arrays(size: int, 
                          #number of arrays must be above a number that provides 
                          #enough examples to train the model but is not excessively high
                          arrays_amount: int(ge=100, le=100000)):

    
    # Initialize an empty list to store the generated arrays
    arrays = []
    
    # Loop over the specified number of arrays to generate
    for i in range(arrays_amount):
        # Generate an array of size 'size' comprising of numbers from 0 to 1000
        array = [random.uniform(0, 1000) for _ in range(size)]
        
        # Add the generated array to the list of arrays
        arrays.append(array)
    
    return arrays

SIZE = 5               ### ! take from API
ARRAYS_AMOUNT = 900    ### ! take from API

generated_arrays = generate_arrays(SIZE, ARRAYS_AMOUNT) ### ! input the parameters set by the User in the API




# Function takes the training_arrays list of training arrays generated by generate_arrays,
# and splits it randomly into NUMBER_OF_MODELS, keeping the order of the numbers in individual lists
async def split_data_for_models(training_arrays, PartsNumber: int): #maybe change PartsNumber to local variable?
    split_data = [training_arrays[i::PartsNumber] for i in range(PartsNumber)]
    return split_data

split_data_for_models(generated_arrays, NUMBER_OF_MODELS)

#async def calculate_representativeness(training_arrays):
#


#Function trains the ML model using Random Forest Regression
async def train_model():  #Uses the libraries: numpy, matplotlib, pandas
   
    #Importing the dataset
    dataset = pd.read_csv('ENTER_THE_NAME_OF_YOUR_DATASET_HERE.csv')  ### ! CHANGE INPUT
    X = dataset.iloc[:, :-1].values
    y = dataset.iloc[:, -1].values

    #Splitting the dataset into the Training set and Test set
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

    #Training the Random Forest Regression model on the whole dataset
    from sklearn.ensemble import RandomForestRegressor
    regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
    regressor.fit(X_train, y_train)

    #Predicting the Test set results
    y_pred = regressor.predict(X_test)
    np.set_printoptions(precision=2)
    print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

    #Evaluating the Model Performance
    from sklearn.metrics import r2_score
    r2_score(y_test, y_pred)
