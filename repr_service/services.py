import asyncio
import math
import random
from typing import List
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import schemas
import models 

#### We define the representativeness of an object as: 
#### 1/(1 + average_distance_of_k_neighbors)


NUMBER_OF_MODELS: int = 4    # "L" from task description - Default number of parts into which we split 
                             # the whole group of training arrays; also the number of models
                             # from which the averaged prediction will be obtained.
                             # It is _not_ directly editable by the User

SIZE: int = 5  # Default size of one array of numbers that will become a single row 
          # of independent variables in the training data; not editable by the User

ARRAYS_AMOUNT: int = 1000  # Total number of arrays of numbers (each of the size = SIZE) 
                     # on which the model will be initially trained

K_NEAREST_NEIGHBOURS: int = 10 # the number of the nearest neighbours of each analyzed object - 
                          # this number will influence the representativeness analysis



# Function generating a set of arrays of the chosen size 'size' with arrays_amount elements;
# It returns a list of arrays of random numbers to be used as independent variables in ML training
async def generate_arrays(size: int, 
                          #number of arrays must be above a number that provides 
                          #enough examples to train the model but is not excessively high
                          arrays_amount: int(ge=100, le=100000)):

    
    # Initialize an empty list to store the generated arrays
    arrays = []
    
    # Loop over the specified number of arrays to generate
    for i in range(arrays_amount):
        # Generate an array of size 'size' comprising of numbers from 0 to 1000
        array = [random.uniform(0, 1000) for _ in range(size)]
        
        # Add the generated array to the list of arrays
        arrays.append(array)
    
    return arrays


generated_arrays = generate_arrays(SIZE, ARRAYS_AMOUNT) # all arrays of independent variables are generated


# Function takes the training_arrays list of training arrays generated by generate_arrays,
# and splits it randomly into NUMBER_OF_MODELS, keeping the order of the numbers in individual lists
async def split_data_for_models(training_arrays, PartsNumber: int): #maybe change PartsNumber to local variable?
    #total number of independent variables being split into a selected number of groups (=NUMBER_OF_MODELS)
    split_data = [training_arrays[i::PartsNumber] for i in range(PartsNumber)]
    
    # for each of the subsets, we pair every element of the set with representativeness calculated for that element
    
    return split_data


# Function calculating representativeness values for all the objects in a given list
# and filling a dict of the calculated repr. values for each object
async def repr_calc_in_a_set(objects: list):
    #For each object, calculating distances from all other objects
    SublistSize = len(objects)
    ReprDict = []# dictionary of pairs object : representativeness, with the size of the sublist taken by the function
    for position in range(SublistSize):
        # calculating the euclidean distance - squared difference of every pair of numbers
        obj = objects[position]
        distances_sum = 0
        neighbours = [element for element in objects if element != objects[position]]
        neighbours_with_distances = []
        #Calculating the distances to all neighbours to find the K nearest neighbours
        for neighbour in neighbours:
            distance = math.sqrt(sum((a - b)**2 for a, b in zip(obj, neighbour)))
            # adding up all the distances from the current considered object ot the rest of the neighbors
            neighbours_with_distances.append([neighbour, distance])
            
            # print(f"distance = {distance}")  # printing for visual checking of example results
        
        nearest_neighbours = sorted(neighbours_with_distances, key=lambda x: x[1], reverse=True)[:K_NEAREST_NEIGHBOURS]
        # adding up all 10 nearest neighbours' distances for the object
        distances_sum = sum(pair[1] for pair in nearest_neighbours) 
        avg_distance = distances_sum / K_NEAREST_NEIGHBOURS
        representativeness = 1 / (1 + avg_distance)
        ReprDict.append([obj, representativeness]) #appending mutable elements in order to enable feature scaling later













# datasets = 
split_data_for_models(generated_arrays, NUMBER_OF_MODELS)

#async def calculate_representativeness(training_arrays):
#


#Function trains the ML model using Random Forest Regression
async def train_model():  #Uses the libraries: numpy, matplotlib, pandas
   
    #Importing the dataset
    dataset = pd.read_csv('ENTER_THE_NAME_OF_YOUR_DATASET_HERE.csv')  ### ! CHANGE INPUT
    X = dataset.iloc[:, :-1].values ### ! CHANGE INPUT
    
    
    y = dataset.iloc[:, -1].values ### ! CHANGE INPUT

    #Splitting the dataset into the Training set and Test set
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

    #Training the Random Forest Regression model on the whole dataset
    from sklearn.ensemble import RandomForestRegressor
    regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
    regressor.fit(X_train, y_train)

    #Predicting the Test set results
    y_pred = regressor.predict(X_test)
    np.set_printoptions(precision=2)
    print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

    #Evaluating the Model Performance
    from sklearn.metrics import r2_score
    r2_score(y_test, y_pred)
    