import asyncio
from datetime import datetime
import math
from pathlib import Path
import random
from typing import List
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
import joblib
from joblib import dump
from sklearn import base
from sklearn.ensemble import RandomForestRegressor
import schemas
from models import MachineLearningData



from parameters import NUMBER_OF_MODELS, INDVARS_ARRAY_SIZE, ARRAYS_AMOUNT, K_NEAREST_NEIGHBOURS

TRAINED_MODELS_PATH_NAME = 'trained_models' # name of a folder created (once) for all the trained models

### DON'T UNCOMMENT - descriptions only for easier reference of meaning of each global variable

# NUMBER_OF_MODELS: int      # "L" from task description - Default number of parts into which we split 
                             # the whole group of training arrays; also the number of models
                             # from which the averaged prediction will be obtained.
                             # It is _not_ directly editable by the User

# INDVARS_ARRAY_SIZE: int   # Default size of one array of numbers that will become a single row 
                            # of independent variables in the training data; not editable by the User


# ARRAYS_AMOUNT: int # Total number of arrays of numbers (each of the size = SIZE) 
                     # on which the model will be initially trained

# K_NEAREST_NEIGHBOURS: int # the number of the nearest neighbours of each analyzed object - 
                            # this number will influence the representativeness analysis

# REGRESSION_MODEL: RandomForestRegressor() #the type of regression machine learning model that will make the predictions

### END OF DESCRIPTIONS



#### We define the representativeness of an object as: 
#### 1/(1 + average_distance_of_k_neighbors)




# Function generating a set of arrays of the chosen size 'size' with arrays_amount elements;
# It returns a list of arrays of random numbers to be used as independent variables in ML training
def generate_arrays(array_size: int, 
                          #number of arrays must be above a number that provides 
                          #enough examples to train the model but is not excessively high
                          arrays_amount: int):

    
    # Initialize an empty list to store the generated arrays
    arrays = []
    
    # Loop over the specified number of arrays to generate
    for i in range(arrays_amount):
        # Generate an array of size 'size' comprising of numbers from 0 to 100
        array = [random.uniform(0, 100) for _ in range(array_size)]
        
        # Add the generated array to the list of arrays
        arrays.append(array)
    
    return arrays


generated_arrays = generate_arrays(INDVARS_ARRAY_SIZE, ARRAYS_AMOUNT) # all arrays of independent variables are generated


# Function takes the training_arrays list of training arrays generated by generate_arrays,
# and splits it randomly into NUMBER_OF_MODELS, keeping the order of the numbers in individual lists
def split_data_for_models(training_arrays, PartsNumber: int): 
    
    # Create and shuffle indices
    indices = list(range(len(training_arrays)))
    random.shuffle(indices)

    # Split data using shuffled indices
    split_data = [[] for _ in range(PartsNumber)]
    for i, idx in enumerate(indices):
        split_data[i % PartsNumber].append(training_arrays[idx])
  
    split_data = [training_arrays[i::PartsNumber] for i in range(PartsNumber)]
    
    return split_data

split_training_arrays = split_data_for_models(generated_arrays, NUMBER_OF_MODELS) # the global variable NUMBER_OF_MODELS is set in parameters.py
print(split_training_arrays)

# Function calculating representativeness values for all the objects in a given list
# and filling a dict of the calculated repr. values for each object
def repr_calc_in_a_set(objects: list):
    #For each object, calculating distances from all other objects
    sublist_size = len(objects)
    repr_dict = []# dictionary of pairs object : representativeness, with the size of the sublist taken by the function
    for position in range(sublist_size):
        # calculating the euclidean distance - squared difference of every pair of numbers
        obj = objects[position]
        distances_sum = 0
        neighbours = [element for element in objects if element != objects[position]]
        neighbours_with_distances = []
        #Calculating the distances to all neighbours to find the K nearest neighbours
        for neighbour in neighbours:
            distance = math.sqrt(sum((a - b)**2 for a, b in zip(obj, neighbour)))
            # adding up all the distances from the current considered object ot the rest of the neighbors
            neighbours_with_distances.append([neighbour, distance])
            
            # print(f"distance = {distance}")  # printing for visual checking of example results
        
        nearest_neighbours = sorted(neighbours_with_distances, key=lambda x: x[1], reverse=True)[:K_NEAREST_NEIGHBOURS]
        # adding up all K nearest neighbours' distances for the object, taking the average and calculating representativeness based on it
        distances_sum = sum(obj_and_dist[1] for obj_and_dist in nearest_neighbours) 
        avg_distance = distances_sum / K_NEAREST_NEIGHBOURS
        representativeness = 1 / (1 + avg_distance)
        # appending the representativeness value to a list of objects mapped to their repr. values
        repr_dict.append([obj, representativeness]) #appending mutable elements in order to enable feature scaling later
    #print(f"list of representativeness:")
    #print(repr_dict) #just for value checking/program observation
    return(repr_dict)

class RepresentativenessDictionary:
    dictionary = split_data_for_models(generate_arrays(INDVARS_ARRAY_SIZE, ARRAYS_AMOUNT), NUMBER_OF_MODELS)

model_number = 0




### WORKING AS INTENDED - SYNCHRONOUS VERSION (CHANGE TO ASYNC)


# Function trains a batch of ML regression models 
# and returns a boolean - training success indicator
def train_models(datasets_batch: list[MachineLearningData]) -> list[base.BaseEstimator]:  #Uses the libraries: numpy, matplotlib, pandas
    
    training_start_timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    trained_models = []
    training_success = None

    for dataset in datasets_batch:
        
        # Importing the dataset
        # getting the array of all independent variables into the X variable
        X = [pair[0] for pair in dataset]
        
        # getting the array of all dependent variables into the y variable
        y = [pair[1] for pair in dataset]    

        regressor = RandomForestRegressor(n_estimators = 10, random_state = random.randint(0, 42))
        try:
            regressor.fit(X, y)
            
        except Exception as e:
            print(f"Model training failed with error: {e} (training started at {training_start_timestamp})")
            training_success = False
        
        trained_models.append(regressor)
    
    if len(trained_models) == NUMBER_OF_MODELS:
        training_success = True
        print("training successful")
        return trained_models#, training_success
    else:
        training_success = False
        print("training of one or more models failed")
        return training_success

###### start of async version of models training

async def train_model(dataset: MachineLearningData) -> base.BaseEstimator:
    X = [pair[0] for pair in dataset]
    y = [pair[1] for pair in dataset]

    regressor = RandomForestRegressor(n_estimators=10, random_state=random.randint(0, 42))
    try:
        await asyncio.to_thread(regressor.fit, X, y)  # Offload training to a separate thread
        await asyncio.sleep(5) ## mockup long training time - to check how the trainings are being executed
        return regressor
    except Exception as e:
        print(f"Model training failed with error: {e}")
        return None

async def train_models_async(datasets_batch: list[MachineLearningData]):
    trained_models = []
    training_tasks = [asyncio.create_task(train_model(dataset)) for dataset in datasets_batch]
    j = 0 ### for checking purposes
    for training_task in training_tasks:
        model: base.BaseEstimator = await training_task
        print(f"model number {j} trained") ### for checking purposes
        j += 1 ### for checking purposes
        if model:  # Only append successful models
            trained_models.append(model)

    return trained_models

# Example usage with asyncio loop
async def main() -> list[base.BaseEstimator]:
    objects_to_representations_batch = [...] # this will become a new batch of training data -
                                      # - a mockup of new data delivered by the User to train new models


    for training_array in split_training_arrays:
        object_to_representation = repr_calc_in_a_set(training_array)
        objects_to_representations_batch.append(object_to_representation)
        #################
    

    trained_models = await train_models_async(objects_to_representations_batch)
    return trained_models
    # Use the trained models...

#if __name__ == "__main__":
   # asyncio.run(main())

###### end of async version of model training    


# Function saves the model as .pkl in a special folder (creates the folder if it didn't exist before)
def dump_models(trained_models: list[base.BaseEstimator]):    ###### WORK ON END NUMERATOR
    # getting the timestamp for the current machine learning model, saving it with this timestamp in the name
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")


    # Checking if the /trained_models folder exists, creating a new one if a folder of this name isn't found
    #models_foldername = 'trained_models'
    models_folder_path = Path(TRAINED_MODELS_PATH_NAME)
    try:
        #if not os.path.exists(models_folder_path):
        if not models_folder_path.exists():
            
            Path.mkdir(models_folder_path)
            print(f"Creating a folder for the trained models: {models_folder_path}")
    except:
        print("A problem occurred when trying to create a new folder ")
    print(f"trained_models: {trained_models}")
    for end_numerator in range(len(trained_models)):
        trained_model_path = models_folder_path.joinpath(f"model_{timestamp}_{end_numerator}.pkl")
        trained_model = trained_models[end_numerator]
        dump(trained_model, trained_model_path)
    



    #################################################################################
    ### This part of code would allow the developers to test the model's accuracy ###
    # Splitting the dataset into the Training set and Test set
    #from sklearn.model_selection import train_test_split
    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

    # Training the Random Forest Regression model on the whole dataset
    #from sklearn.ensemble import RandomForestRegressor
    #regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)
    #regressor.fit(X_train, y_train)

    
    # Predicting the Test set results
    #y_pred = regressor.predict(X_test)
    #np.set_printoptions(precision=2)
    #print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))

    #Evaluating the Model Performance
    #from sklearn.metrics import r2_score
    #r2_score(y_test, y_pred)
    
    ### End of accuracy testing code ###
    ####################################

# Function that gets the recent batch of trained models. The number of the models in one batch is defined globally - not editable by the User
def get_recent_models():
    
    models_filenames = os.listdir("trained_models")
    print(models_filenames) #OK, works
    models_filepaths: Path = []
    for model_filename in models_filenames:
        model_path = os.path.join("trained_models", model_filename)
        models_filepaths.append(model_path)
        #models_filepaths.append(model_filename)
    # Sortowanie plików według czasu modyfikacji
    print(f"models filepaths: {models_filepaths}")
    models_filepaths.sort(key=os.path.getmtime, reverse=True)
    print(f"SORTED models filepaths: {models_filepaths}")

    # Loading the recently trained group of models
    predicting_models = []
    for i in range(NUMBER_OF_MODELS):
        print(f"model filepath to grab number {i}: {models_filepaths[i]}")
        model_to_grab = joblib.load(models_filepaths[i])
        predicting_models.append(model_to_grab)
    print(f"predicting_models: {predicting_models}")
    return predicting_models



# Function that makes a new prediction from a set of new independent variables
def predict_from_models_array(models: list[RandomForestRegressor]): ###, new_indvars: list[[float]] | None = None
    new_indvars = [[5.3], [34.111], [99.1], [0.9], [10.4]] #test input, remove later and only take input from the user
    predicted_values_sum = 0
    for model in models:
        predicted_value: float = model.predict(np.array(new_indvars).reshape(1, -1))
        predicted_values_sum += predicted_value
    average_prediction = predicted_values_sum / len(new_indvars)
    print(f"Average prediction from {NUMBER_OF_MODELS} trained models: {average_prediction}") # just for checking
    return(average_prediction)
    
objects_to_representations_batch = [] # this will become a new batch of training data -
                                      # - a mockup of new data delivered by the User to train new models


for training_array in split_training_arrays:
    object_to_representation = repr_calc_in_a_set(training_array)
    objects_to_representations_batch.append(object_to_representation)
    #################

dump_models(train_models(objects_to_representations_batch))

# def get_models_from_async_trainings():
    
#     #loop = asyncio.get_event_loop()  # Get the running event loop
#     print("running async model trainings...\n")
#     new_models_to_dump = main()
#     dump_models(new_models_to_dump)

# get_models_from_async_trainings()


async def get_models_from_async_trainings():
    print("running async model trainings...\n")
    new_models_to_dump = await main()  # Assuming main is async
    dump_models(new_models_to_dump)

asyncio.run(get_models_from_async_trainings())

print("predicting from recent models...\n")
predict_from_models_array(get_recent_models())




# def get_training_status():
#   """
#   Returns a dictionary of informations on the status of the ML process.

#   Returned values:
#     status: "Error", "model training still in progress", "model training completed"
#     error_message: an optional message about the error if it occured
#     start_time, end_time: time when the model training started and when it ended
#   """

#   status = "model training still in progress"
#   error_message = None
#   start_time = _start_time

#   if _training_failed:
#     status = "Error"
#     error_message = _error_message

#   if _training_completed:
#     status = "model training completed"
#     end_time = _end_time

#   return {
#     "status": status,
#     "error_message": error_message,
#     "start_time": start_time.isoformat(),
#     "end_time": end_time.isoformat() if end_time else None,
#   }

# #class status_check:
#   # Zmienne do śledzenia statusu
#   _training_failed = False
#   _error_message = None
#   _start_time = None
#   _training_completed = False
#   _end_time = None

#   # Function that initiates the training of the model.
#   def start_training():
#     # setting the global variables for status observation
#     _training_failed, _error_message, _start_time, _training_completed, _end_time

#     _training_failed = False
#     _error_message = None
#     _start_time = datetime.now()
#     _training_completed = False
#     _end_time = None
#   # Function to be called when the model traiing ends - it updates the status variables
#   def end_training(success=True):
    
#     """
#     Argumenty:
#       success: True, if the training finished successfully , otherwise False. ### ! prepare the 'success' variable: it should check 
#                                                                               ### if the full set of dependent variables is delivered
#                                                                               ### at the end of the model training.
#     """

#     _training_failed, _error_message, _training_completed, _end_time

#     _training_completed = True 
#     _end_time = datetime.now()

#     if not success:
#       _training_failed = True
#       _error_message = "An error occurred during the model training."

